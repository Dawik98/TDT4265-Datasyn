{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](img/task_1a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "![](img/task_1b_1.jpg)\n",
    "![](img/task_1b_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](img/task2c_train_loss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "In the first layer we have 784x64 weights and 64 biases, and in the second layer we have 64x10 weights, and we are not adding biases here. It will result in 785\\*64+64\\*10=50880 parameters, which is the same as sum of all elemts in weight matricies (since we are using the bias trick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "![](img/task3.png)\n",
    "\n",
    "In the image above we can see how adding the \"tricks\" changes the learning rate and accuracy of thge model. All changes can bee compared to the original model (blue). First I changed the weight initialization method (orange). This improved the end validation accuracy from 92% to about 95.5%. This model stopped learning at about the same epoch as the original one. Next I changed the sigmoid function (green). This lead to even higher validation accuracy at about 96% and the network stopped learning at epoch 18. We can also see that learning speed has improved aswell. We can however see that the network might overfit a bit, since the validation loss is slowly increasing after about 5000 training steps. The training accuracy of the network ends up at 100%. It might be that we should use a bigger dataset to be able to bring the validation accuracy closer to 100%. The last change was adding the momentum (red), when updating the weights. This resultet in very similiar to the previous one. The network stops learning a bit earlier at epoch 14. It also seems that the validation loss and accuracy is a bit more \"noisy\". Here the model also start to overfit slightly, as the validation loss increases after about 4000 training steps. However since we have early stopping the overfitting doesn't become a big problem. The end validation accuracy didn't increase this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4ab)\n",
    "\n",
    "![](img/task4ab.png)\n",
    "\n",
    "We can see that the network with 32 hidden units, gives much worse results than the other two. Reason for that might be that the model is too simple and it is underfitting. However when we make model more complex with 128 hidden units, we can see improvement in the validation accuracy, without any obvious signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "\n",
    "![](img/task4d.png)\n",
    "\n",
    "Here we have two neural networks:\n",
    "* original with 64-10 units in two hidden layers, with 50880 parameters\n",
    "* new network with 60-60-10 units in three layers, with 51300 parameters\n",
    "\n",
    "As we can see the performance is very similiar, without any big benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "\n",
    "\n",
    "![](img/task4e.png)\n",
    "\n",
    "Here we have three neural networks:\n",
    "* original with 64-10 units in two hidden layers, with 50880 parameters\n",
    "* three layer network with 60-60-10 units, with 51300 parameters\n",
    "* new 11 layer network with 64x10-10 units, with 87744 parameters\n",
    "\n",
    "As we can see the performence got clearly worse. The main reason is that our model is far too complex for this simple problem. The other reason might be \"The Vanishing Gradient Problem\", which is common in the network with a lot of layers. The main problem are the small derivatives of the sigmaoid function that are multiplied together in the chainrule in backpropagation to update the weights. That means that some layers will get very small updates, and the learning will not be efficient. We can see that in task 4b we increased number of nodes in a layer and got better performance, however increasing number of layers significantly had the opposite effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}